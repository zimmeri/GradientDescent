# GradientDescent
Batch and Gradient Descent algorithms with different loss functions
Stochastic Gradient Descent and Batch gradient Descent using 8 combinations of log and hinge algorithms with and without 
regularization to optimize accuracy 


Used data/given/train.tsv to train the algorithms
Used data/given/test.tsv to test the accuracy and precision of algorithms

Batch gradient descent algorithms are located in src/bgd.py
Stochastic gradient descent algorithms are located in src/sgd.py

Was able to achieve maximum accuracy of around 80%.  While these accuracies are not optimal, this was a 2 week project where 
I was unable to fine tune the algorithms.

More analysis can be found in report/report.pdf with accompanying questions in handout.pdf.
